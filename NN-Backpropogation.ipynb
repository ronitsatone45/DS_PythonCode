{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T04:10:59.646604Z",
     "start_time": "2021-09-14T04:10:31.655044Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T04:16:05.811789Z",
     "start_time": "2021-09-14T04:11:39.302285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.6.0-cp38-cp38-win_amd64.whl (423.2 MB)\n",
      "Collecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (0.36.2)\n",
      "Collecting clang~=5.0\n",
      "  Downloading clang-5.0.tar.gz (30 kB)\n",
      "Collecting numpy~=1.19.2\n",
      "  Downloading numpy-1.19.5-cp38-cp38-win_amd64.whl (13.3 MB)\n",
      "Requirement already satisfied: keras~=2.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.13.0-py3-none-any.whl (132 kB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Collecting tensorflow-estimator~=2.6\n",
      "  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp38-cp38-win_amd64.whl (2.7 MB)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (3.17.3)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting tensorboard~=2.6\n",
      "  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting grpcio<2.0,>=1.37.0\n",
      "  Downloading grpcio-1.40.0-cp38-cp38-win_amd64.whl (3.2 MB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.25.1)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.2)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.5.30)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (4.0.0)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Building wheels for collected packages: clang, termcolor\n",
      "  Building wheel for clang (setup.py): started\n",
      "  Building wheel for clang (setup.py): finished with status 'done'\n",
      "  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30702 sha256=bd71ed5ebf87f9fa49cd467ae7514b6aa745ff6c5db0618069de047a03af0969\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\f1\\60\\77\\22b9b5887bd47801796a856f47650d9789c74dc3161a26d608\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=9097f9a68e72a975e149a00fa7a16dbd486d6e6f3f60d4b311e7f2bbe4dcddf1\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\a0\\16\\9c\\5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built clang termcolor\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, requests-oauthlib, google-auth, tensorboard-plugin-wit, tensorboard-data-server, numpy, markdown, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, flatbuffers, clang, astunparse, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.1\n",
      "    Uninstalling numpy-1.20.1:\n",
      "      Successfully uninstalled numpy-1.20.1\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.10.0\n",
      "    Uninstalling h5py-2.10.0:\n",
      "      Successfully uninstalled h5py-2.10.0\n",
      "Successfully installed absl-py-0.13.0 astunparse-1.6.3 clang-5.0 flatbuffers-1.12 gast-0.4.0 google-auth-1.35.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.40.0 h5py-3.1.0 keras-preprocessing-1.1.2 markdown-3.3.4 numpy-1.19.5 oauthlib-3.1.1 opt-einsum-3.3.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.7.2 tensorboard-2.6.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.6.0 tensorflow-estimator-2.6.0 termcolor-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T04:22:29.748204Z",
     "start_time": "2021-09-14T04:22:12.283926Z"
    },
    "execution": {
     "iopub.execute_input": "2021-09-13T06:58:23.941380Z",
     "iopub.status.busy": "2021-09-13T06:58:23.940499Z",
     "iopub.status.idle": "2021-09-13T06:58:29.367729Z",
     "shell.execute_reply": "2021-09-13T06:58:29.366883Z",
     "shell.execute_reply.started": "2021-09-13T06:58:23.941331Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create your first MLP in Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "#pip install keras\n",
    "#https://www.tensorflow.org/install/pip#windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T04:23:28.862553Z",
     "start_time": "2021-09-14T04:23:28.796344Z"
    },
    "execution": {
     "iopub.execute_input": "2021-09-13T06:58:29.370066Z",
     "iopub.status.busy": "2021-09-13T06:58:29.369745Z",
     "iopub.status.idle": "2021-09-13T06:58:29.396680Z",
     "shell.execute_reply": "2021-09-13T06:58:29.395865Z",
     "shell.execute_reply.started": "2021-09-13T06:58:29.370039Z"
    }
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.data (1).csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T04:23:30.771671Z",
     "start_time": "2021-09-14T04:23:30.251738Z"
    },
    "execution": {
     "iopub.execute_input": "2021-09-13T06:58:29.398261Z",
     "iopub.status.busy": "2021-09-13T06:58:29.397993Z",
     "iopub.status.idle": "2021-09-13T06:58:29.515703Z",
     "shell.execute_reply": "2021-09-13T06:58:29.514657Z",
     "shell.execute_reply.started": "2021-09-13T06:58:29.398235Z"
    }
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T04:23:35.684713Z",
     "start_time": "2021-09-14T04:23:35.664618Z"
    },
    "execution": {
     "iopub.execute_input": "2021-09-13T06:58:29.519583Z",
     "iopub.status.busy": "2021-09-13T06:58:29.519237Z",
     "iopub.status.idle": "2021-09-13T06:58:29.537271Z",
     "shell.execute_reply": "2021-09-13T06:58:29.536336Z",
     "shell.execute_reply.started": "2021-09-13T06:58:29.519549Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T04:24:12.144401Z",
     "start_time": "2021-09-14T04:23:36.645569Z"
    },
    "execution": {
     "iopub.execute_input": "2021-09-13T06:58:29.540109Z",
     "iopub.status.busy": "2021-09-13T06:58:29.539675Z",
     "iopub.status.idle": "2021-09-13T06:58:43.916034Z",
     "shell.execute_reply": "2021-09-13T06:58:43.914813Z",
     "shell.execute_reply.started": "2021-09-13T06:58:29.540074Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "52/52 [==============================] - 2s 10ms/step - loss: 10.6943 - accuracy: 0.6148 - val_loss: 2.0071 - val_accuracy: 0.5551\n",
      "Epoch 2/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.8435 - accuracy: 0.5506 - val_loss: 1.6703 - val_accuracy: 0.5984\n",
      "Epoch 3/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.4913 - accuracy: 0.5875 - val_loss: 1.4425 - val_accuracy: 0.6417\n",
      "Epoch 4/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.3538 - accuracy: 0.6031 - val_loss: 1.2719 - val_accuracy: 0.6614\n",
      "Epoch 5/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.2238 - accuracy: 0.6109 - val_loss: 1.2060 - val_accuracy: 0.6457\n",
      "Epoch 6/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.1472 - accuracy: 0.6284 - val_loss: 1.1374 - val_accuracy: 0.6378\n",
      "Epoch 7/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.0586 - accuracy: 0.6576 - val_loss: 1.0582 - val_accuracy: 0.6575\n",
      "Epoch 8/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.9979 - accuracy: 0.6498 - val_loss: 1.3287 - val_accuracy: 0.5866\n",
      "Epoch 9/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.9996 - accuracy: 0.6498 - val_loss: 1.0035 - val_accuracy: 0.6535\n",
      "Epoch 10/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.9435 - accuracy: 0.6537 - val_loss: 0.9610 - val_accuracy: 0.6614\n",
      "Epoch 11/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.9070 - accuracy: 0.6323 - val_loss: 0.8947 - val_accuracy: 0.6457\n",
      "Epoch 12/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8547 - accuracy: 0.6634 - val_loss: 0.8537 - val_accuracy: 0.6535\n",
      "Epoch 13/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8416 - accuracy: 0.6479 - val_loss: 0.8260 - val_accuracy: 0.6693\n",
      "Epoch 14/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8183 - accuracy: 0.6381 - val_loss: 0.8177 - val_accuracy: 0.6378\n",
      "Epoch 15/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7878 - accuracy: 0.6342 - val_loss: 0.7612 - val_accuracy: 0.6457\n",
      "Epoch 16/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.6595 - val_loss: 0.7471 - val_accuracy: 0.6575\n",
      "Epoch 17/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7587 - accuracy: 0.6401 - val_loss: 0.7280 - val_accuracy: 0.6496\n",
      "Epoch 18/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7390 - accuracy: 0.6595 - val_loss: 0.7230 - val_accuracy: 0.6339\n",
      "Epoch 19/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7177 - accuracy: 0.6693 - val_loss: 0.7134 - val_accuracy: 0.6772\n",
      "Epoch 20/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6861 - accuracy: 0.6712 - val_loss: 0.6999 - val_accuracy: 0.6457\n",
      "Epoch 21/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6775 - accuracy: 0.6770 - val_loss: 0.6783 - val_accuracy: 0.6378\n",
      "Epoch 22/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6614 - accuracy: 0.6907 - val_loss: 0.7332 - val_accuracy: 0.6772\n",
      "Epoch 23/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6369 - accuracy: 0.6868 - val_loss: 0.6653 - val_accuracy: 0.6969\n",
      "Epoch 24/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6513 - accuracy: 0.6790 - val_loss: 0.6445 - val_accuracy: 0.6614\n",
      "Epoch 25/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6256 - accuracy: 0.6887 - val_loss: 0.6266 - val_accuracy: 0.6654\n",
      "Epoch 26/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6551 - accuracy: 0.6809 - val_loss: 0.6252 - val_accuracy: 0.6890\n",
      "Epoch 27/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.7198 - val_loss: 0.6031 - val_accuracy: 0.6772\n",
      "Epoch 28/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6064 - accuracy: 0.6907 - val_loss: 0.5901 - val_accuracy: 0.6811\n",
      "Epoch 29/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5915 - accuracy: 0.7062 - val_loss: 0.5835 - val_accuracy: 0.6811\n",
      "Epoch 30/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6400 - accuracy: 0.6868 - val_loss: 0.6383 - val_accuracy: 0.6850\n",
      "Epoch 31/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6131 - accuracy: 0.6926 - val_loss: 0.6029 - val_accuracy: 0.7087\n",
      "Epoch 32/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6154 - accuracy: 0.7004 - val_loss: 0.5802 - val_accuracy: 0.7126\n",
      "Epoch 33/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6096 - accuracy: 0.6984 - val_loss: 0.5741 - val_accuracy: 0.7087\n",
      "Epoch 34/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5843 - accuracy: 0.7004 - val_loss: 0.6206 - val_accuracy: 0.6732\n",
      "Epoch 35/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6125 - accuracy: 0.6907 - val_loss: 0.5739 - val_accuracy: 0.7126\n",
      "Epoch 36/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6092 - accuracy: 0.7023 - val_loss: 0.7224 - val_accuracy: 0.6142\n",
      "Epoch 37/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.6038 - accuracy: 0.7004 - val_loss: 0.6463 - val_accuracy: 0.6969\n",
      "Epoch 38/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5770 - accuracy: 0.7140 - val_loss: 0.5688 - val_accuracy: 0.6969\n",
      "Epoch 39/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6001 - accuracy: 0.7121 - val_loss: 0.5705 - val_accuracy: 0.7165\n",
      "Epoch 40/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5857 - accuracy: 0.7218 - val_loss: 0.6887 - val_accuracy: 0.6811\n",
      "Epoch 41/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6012 - accuracy: 0.7043 - val_loss: 0.5718 - val_accuracy: 0.7087\n",
      "Epoch 42/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5826 - accuracy: 0.7140 - val_loss: 0.5614 - val_accuracy: 0.7126\n",
      "Epoch 43/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5725 - accuracy: 0.7160 - val_loss: 0.5781 - val_accuracy: 0.7008\n",
      "Epoch 44/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5831 - accuracy: 0.7160 - val_loss: 0.6093 - val_accuracy: 0.6929\n",
      "Epoch 45/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6215 - accuracy: 0.6809 - val_loss: 0.5790 - val_accuracy: 0.7205\n",
      "Epoch 46/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6711 - accuracy: 0.6654 - val_loss: 0.5651 - val_accuracy: 0.7126\n",
      "Epoch 47/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6066 - accuracy: 0.7121 - val_loss: 0.6570 - val_accuracy: 0.6299\n",
      "Epoch 48/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5534 - accuracy: 0.7315 - val_loss: 0.5601 - val_accuracy: 0.7244\n",
      "Epoch 49/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5720 - accuracy: 0.7198 - val_loss: 0.6125 - val_accuracy: 0.6850\n",
      "Epoch 50/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5650 - accuracy: 0.7237 - val_loss: 0.5963 - val_accuracy: 0.6772\n",
      "Epoch 51/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5909 - accuracy: 0.7043 - val_loss: 0.7636 - val_accuracy: 0.5630\n",
      "Epoch 52/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5935 - accuracy: 0.7121 - val_loss: 0.7393 - val_accuracy: 0.5591\n",
      "Epoch 53/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5860 - accuracy: 0.7237 - val_loss: 0.5748 - val_accuracy: 0.7244\n",
      "Epoch 54/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5638 - accuracy: 0.7354 - val_loss: 0.5640 - val_accuracy: 0.7441\n",
      "Epoch 55/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5545 - accuracy: 0.7412 - val_loss: 0.5490 - val_accuracy: 0.7244\n",
      "Epoch 56/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5970 - accuracy: 0.7160 - val_loss: 0.5749 - val_accuracy: 0.7323\n",
      "Epoch 57/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5576 - accuracy: 0.7276 - val_loss: 0.5709 - val_accuracy: 0.7205\n",
      "Epoch 58/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5783 - accuracy: 0.6926 - val_loss: 0.5455 - val_accuracy: 0.7323\n",
      "Epoch 59/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5486 - accuracy: 0.7198 - val_loss: 0.5910 - val_accuracy: 0.7047\n",
      "Epoch 60/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6230 - accuracy: 0.6693 - val_loss: 0.5979 - val_accuracy: 0.6772\n",
      "Epoch 61/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5925 - accuracy: 0.7179 - val_loss: 0.5506 - val_accuracy: 0.7165\n",
      "Epoch 62/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.7218 - val_loss: 0.5928 - val_accuracy: 0.7126\n",
      "Epoch 63/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5730 - accuracy: 0.7198 - val_loss: 0.5862 - val_accuracy: 0.7008\n",
      "Epoch 64/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.7296 - val_loss: 0.5738 - val_accuracy: 0.7126\n",
      "Epoch 65/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5718 - accuracy: 0.6946 - val_loss: 0.6068 - val_accuracy: 0.6969\n",
      "Epoch 66/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5403 - accuracy: 0.7335 - val_loss: 0.6259 - val_accuracy: 0.6575\n",
      "Epoch 67/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5551 - accuracy: 0.7296 - val_loss: 0.5845 - val_accuracy: 0.7087\n",
      "Epoch 68/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5631 - accuracy: 0.7218 - val_loss: 0.5701 - val_accuracy: 0.7087\n",
      "Epoch 69/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5593 - accuracy: 0.6965 - val_loss: 0.6797 - val_accuracy: 0.5827\n",
      "Epoch 70/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6008 - accuracy: 0.7179 - val_loss: 0.6559 - val_accuracy: 0.6299\n",
      "Epoch 71/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5642 - accuracy: 0.7101 - val_loss: 0.5842 - val_accuracy: 0.6850\n",
      "Epoch 72/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5816 - accuracy: 0.7140 - val_loss: 0.5500 - val_accuracy: 0.7323\n",
      "Epoch 73/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.5759 - accuracy: 0.7218 - val_loss: 0.6016 - val_accuracy: 0.7087\n",
      "Epoch 74/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.5796 - accuracy: 0.7179 - val_loss: 0.6146 - val_accuracy: 0.6890\n",
      "Epoch 75/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5830 - accuracy: 0.7315 - val_loss: 0.5284 - val_accuracy: 0.7323\n",
      "Epoch 76/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5491 - accuracy: 0.7296 - val_loss: 0.6107 - val_accuracy: 0.6969\n",
      "Epoch 77/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5556 - accuracy: 0.7237 - val_loss: 0.5537 - val_accuracy: 0.7126\n",
      "Epoch 78/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5893 - accuracy: 0.7121 - val_loss: 0.5982 - val_accuracy: 0.7283\n",
      "Epoch 79/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5756 - accuracy: 0.7140 - val_loss: 0.5481 - val_accuracy: 0.7165\n",
      "Epoch 80/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5417 - accuracy: 0.7529 - val_loss: 0.5404 - val_accuracy: 0.7402\n",
      "Epoch 81/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5660 - accuracy: 0.7179 - val_loss: 0.5380 - val_accuracy: 0.7323\n",
      "Epoch 82/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5788 - accuracy: 0.7160 - val_loss: 0.5569 - val_accuracy: 0.7087\n",
      "Epoch 83/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5880 - accuracy: 0.7218 - val_loss: 0.5374 - val_accuracy: 0.7362\n",
      "Epoch 84/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5516 - accuracy: 0.7296 - val_loss: 0.5337 - val_accuracy: 0.7362\n",
      "Epoch 85/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5476 - accuracy: 0.7198 - val_loss: 0.5692 - val_accuracy: 0.7165\n",
      "Epoch 86/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5666 - accuracy: 0.6926 - val_loss: 0.5299 - val_accuracy: 0.7402\n",
      "Epoch 87/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5454 - accuracy: 0.7315 - val_loss: 0.5423 - val_accuracy: 0.7480\n",
      "Epoch 88/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5905 - accuracy: 0.7101 - val_loss: 0.6050 - val_accuracy: 0.6969\n",
      "Epoch 89/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5440 - accuracy: 0.7179 - val_loss: 0.6154 - val_accuracy: 0.6969\n",
      "Epoch 90/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.7218 - val_loss: 0.6823 - val_accuracy: 0.6063\n",
      "Epoch 91/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5518 - accuracy: 0.7257 - val_loss: 0.6074 - val_accuracy: 0.7126\n",
      "Epoch 92/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5403 - accuracy: 0.7296 - val_loss: 0.5785 - val_accuracy: 0.7165\n",
      "Epoch 93/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5483 - accuracy: 0.7101 - val_loss: 0.5519 - val_accuracy: 0.7362\n",
      "Epoch 94/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5324 - accuracy: 0.7471 - val_loss: 0.5463 - val_accuracy: 0.7165\n",
      "Epoch 95/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5406 - accuracy: 0.7490 - val_loss: 0.5378 - val_accuracy: 0.7559\n",
      "Epoch 96/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5407 - accuracy: 0.7374 - val_loss: 0.5574 - val_accuracy: 0.7520\n",
      "Epoch 97/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5409 - accuracy: 0.7276 - val_loss: 0.5451 - val_accuracy: 0.7441\n",
      "Epoch 98/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5520 - accuracy: 0.7198 - val_loss: 0.5336 - val_accuracy: 0.7323\n",
      "Epoch 99/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5252 - accuracy: 0.7432 - val_loss: 0.5778 - val_accuracy: 0.7205\n",
      "Epoch 100/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5434 - accuracy: 0.7412 - val_loss: 0.5331 - val_accuracy: 0.7283\n",
      "Epoch 101/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5460 - accuracy: 0.7393 - val_loss: 0.5355 - val_accuracy: 0.7283\n",
      "Epoch 102/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5639 - accuracy: 0.7257 - val_loss: 0.5680 - val_accuracy: 0.6890\n",
      "Epoch 103/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5758 - accuracy: 0.7043 - val_loss: 0.5307 - val_accuracy: 0.7441\n",
      "Epoch 104/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5531 - accuracy: 0.7354 - val_loss: 0.6081 - val_accuracy: 0.6614\n",
      "Epoch 105/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.7451 - val_loss: 0.5415 - val_accuracy: 0.7047\n",
      "Epoch 106/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5330 - accuracy: 0.7276 - val_loss: 0.5651 - val_accuracy: 0.7205\n",
      "Epoch 107/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.7237 - val_loss: 0.5930 - val_accuracy: 0.7244\n",
      "Epoch 108/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5375 - accuracy: 0.7471 - val_loss: 0.5692 - val_accuracy: 0.7244\n",
      "Epoch 109/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5315 - accuracy: 0.7218 - val_loss: 0.6129 - val_accuracy: 0.7165\n",
      "Epoch 110/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5313 - accuracy: 0.7276 - val_loss: 0.5253 - val_accuracy: 0.7638\n",
      "Epoch 111/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5336 - accuracy: 0.7432 - val_loss: 0.5437 - val_accuracy: 0.7559\n",
      "Epoch 112/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5324 - accuracy: 0.7471 - val_loss: 0.5675 - val_accuracy: 0.7165\n",
      "Epoch 113/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5242 - accuracy: 0.7257 - val_loss: 0.5297 - val_accuracy: 0.7520\n",
      "Epoch 114/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5404 - accuracy: 0.7315 - val_loss: 0.5555 - val_accuracy: 0.7362\n",
      "Epoch 115/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5588 - accuracy: 0.7198 - val_loss: 0.5314 - val_accuracy: 0.7323\n",
      "Epoch 116/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.7335 - val_loss: 0.5517 - val_accuracy: 0.7520\n",
      "Epoch 117/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5354 - accuracy: 0.7276 - val_loss: 0.5604 - val_accuracy: 0.7323\n",
      "Epoch 118/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.7121 - val_loss: 0.5625 - val_accuracy: 0.7244\n",
      "Epoch 119/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5262 - accuracy: 0.7412 - val_loss: 0.5916 - val_accuracy: 0.7087\n",
      "Epoch 120/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5255 - accuracy: 0.7374 - val_loss: 0.6105 - val_accuracy: 0.7244\n",
      "Epoch 121/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5405 - accuracy: 0.7335 - val_loss: 0.5265 - val_accuracy: 0.7402\n",
      "Epoch 122/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.7529 - val_loss: 0.5226 - val_accuracy: 0.7598\n",
      "Epoch 123/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5421 - accuracy: 0.7257 - val_loss: 0.5177 - val_accuracy: 0.7441\n",
      "Epoch 124/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5175 - accuracy: 0.7529 - val_loss: 0.5258 - val_accuracy: 0.7441\n",
      "Epoch 125/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5401 - accuracy: 0.7335 - val_loss: 0.5319 - val_accuracy: 0.7362\n",
      "Epoch 126/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5447 - accuracy: 0.7296 - val_loss: 0.5457 - val_accuracy: 0.7362\n",
      "Epoch 127/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5365 - accuracy: 0.7121 - val_loss: 0.5184 - val_accuracy: 0.7480\n",
      "Epoch 128/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7374 - val_loss: 0.5217 - val_accuracy: 0.7520\n",
      "Epoch 129/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5359 - accuracy: 0.7451 - val_loss: 0.5500 - val_accuracy: 0.7205\n",
      "Epoch 130/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5243 - accuracy: 0.7412 - val_loss: 0.5192 - val_accuracy: 0.7480\n",
      "Epoch 131/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5614 - accuracy: 0.6984 - val_loss: 0.5937 - val_accuracy: 0.7126\n",
      "Epoch 132/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.6868 - val_loss: 0.5684 - val_accuracy: 0.7165\n",
      "Epoch 133/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5259 - accuracy: 0.7393 - val_loss: 0.5300 - val_accuracy: 0.7480\n",
      "Epoch 134/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5349 - accuracy: 0.7354 - val_loss: 0.5324 - val_accuracy: 0.7480\n",
      "Epoch 135/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 0.7510 - val_loss: 0.5421 - val_accuracy: 0.7441\n",
      "Epoch 136/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7568 - val_loss: 0.5554 - val_accuracy: 0.7323\n",
      "Epoch 137/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5395 - accuracy: 0.7315 - val_loss: 0.5984 - val_accuracy: 0.6732\n",
      "Epoch 138/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5267 - accuracy: 0.7335 - val_loss: 0.5333 - val_accuracy: 0.7598\n",
      "Epoch 139/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5275 - accuracy: 0.7568 - val_loss: 0.5556 - val_accuracy: 0.7008\n",
      "Epoch 140/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5212 - accuracy: 0.7432 - val_loss: 0.5282 - val_accuracy: 0.7559\n",
      "Epoch 141/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5383 - accuracy: 0.7374 - val_loss: 0.5225 - val_accuracy: 0.7402\n",
      "Epoch 142/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7451 - val_loss: 0.5200 - val_accuracy: 0.7480\n",
      "Epoch 143/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5544 - accuracy: 0.7218 - val_loss: 0.5165 - val_accuracy: 0.7717\n",
      "Epoch 144/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5403 - accuracy: 0.7296 - val_loss: 0.5325 - val_accuracy: 0.7205\n",
      "Epoch 145/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5437 - accuracy: 0.7335 - val_loss: 0.5443 - val_accuracy: 0.7165\n",
      "Epoch 146/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5329 - accuracy: 0.7237 - val_loss: 0.5559 - val_accuracy: 0.7126\n",
      "Epoch 147/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.7490 - val_loss: 0.5245 - val_accuracy: 0.7323\n",
      "Epoch 148/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7568 - val_loss: 0.5347 - val_accuracy: 0.7205\n",
      "Epoch 149/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5327 - accuracy: 0.7374 - val_loss: 0.5194 - val_accuracy: 0.7441\n",
      "Epoch 150/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7568 - val_loss: 0.5306 - val_accuracy: 0.7244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1da371286a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T04:24:18.936540Z",
     "start_time": "2021-09-14T04:24:18.567051Z"
    },
    "execution": {
     "iopub.execute_input": "2021-09-13T06:58:43.918250Z",
     "iopub.status.busy": "2021-09-13T06:58:43.917947Z",
     "iopub.status.idle": "2021-09-13T06:58:44.074361Z",
     "shell.execute_reply": "2021-09-13T06:58:44.073296Z",
     "shell.execute_reply.started": "2021-09-13T06:58:43.918221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 3ms/step - loss: 0.5191 - accuracy: 0.7474\n",
      "accuracy: 74.74%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
